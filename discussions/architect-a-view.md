# 分布式 AI 助手系统架构方案（专家A视角）

## 1. 目标与约束

### 1.1 业务目标
- 构建一个“本地可控 + 云端可扩展”的分布式 AI 助手系统。
- 本地根节点承担用户入口、最小化控制平面、关键隐私策略执行。
- 云端从节点承担算力密集任务（LLM 推理、RAG 检索、工具执行、异步任务）。

### 1.2 硬约束
- **本地根节点**：1核 / 921MB 内存，**无 Docker**。
- **云端从节点**：支持 Docker 镜像部署，可横向扩容。

### 1.3 设计原则
1. **根节点“薄化”**：只保留必须能力（鉴权、路由、状态机、缓存、降级策略）。
2. **云端“重化”**：推理与复杂编排均在容器化从节点执行。
3. **异步优先**：任务队列化，避免根节点阻塞。
4. **可降级运行**：云断连时可提供最低能力（规则回复/本地轻工具）。
5. **安全分层**：本地私密数据最小上云，任务级权限控制。

---

## 2. 总体架构（推荐）

###[A] 控制面（Root 控制）
- 运行在本地根节点（原生二进制/轻量 Python/Go 服务）。
- 职责：
  - 用户请求接入（API/CLI/消息）
  - 会话状态管理（短上下文）
  - 策略引擎（数据是否可上云、是否可调用外部工具）
  - 任务路由（本地执行 vs 云端执行）
  - 健康检查与故障切换

###[B] 数据面（Cloud Worker 执行）
- 运行在云端 Docker 集群。
- 职责：
  - LLM 推理代理（对接多模型）
  - RAG 检索（向量库 + 重排）
  - 工具执行沙箱（浏览器自动化、代码执行、外部 API）
  - 异步任务处理（长任务、批处理、计划任务）

###[C] 通信层
- 根节点与云端之间建议采用：
  - **主通道：HTTPS/gRPC（请求-响应）**
  - **异步通道：消息队列（NATS/Redis Streams/RabbitMQ）**
- 协议要求：
  - 双向认证（mTLS 或签名 token）
  - 幂等任务 ID（防重复执行）
  - 可重试 + 指数退避

---

## 3. 根节点（1核/921MB）架构建议

### 3.1 进程与资源预算
建议单进程或最多双进程，内存目标：
- 主服务：150~250MB
- 本地缓存（LRU + 小型 KV）：50~120MB
- 系统与预留：300MB+
- 避免 Java/重型框架；优先 Go 或 Python + uvloop + 精简依赖。

### 3.2 根节点最小组件
1. **Ingress API**：统一入口，支持流式返回。
2. **Router**：根据任务类型、延迟目标、隐私级别进行路由。
3. **Policy Guard**：敏感信息检测与脱敏（PII masking）。
4. **Session Store（轻量）**：
   - 短会话放内存 + 本地 sqlite 持久化。
   - 不在本地保存大体量 embedding。
5. **Failover Engine**：云不可用时触发降级模式。

### 3.3 不应放在根节点的能力
- 大模型本地推理
- 全量向量检索
- 浏览器/容器沙箱执行
- 大规模日志分析

---

## 4. 云端从节点（Docker）架构建议

### 4.1 服务分层
1. **Gateway Worker**：接收根节点任务，鉴权、限流、审计。
2. **Inference Worker**：模型路由（高质量/低成本/低延迟）。
3. **RAG Worker**：文档切分、索引、召回、重排。
4. **Tool Worker**：外部工具调用与隔离执行。
5. **Task Worker**：异步任务编排（队列消费、重试、超时）。

### 4.2 容器编排建议
- 初期：Docker Compose（低复杂度）
- 成熟期：K8s（自动扩缩容、故障自愈、多可用区）

### 4.3 状态与存储
- 元数据：PostgreSQL
- 缓存与队列：Redis（或 Redis Streams）
- 对象存储：S3 兼容（会话附件、日志归档）
- 向量库：Qdrant / Weaviate / pgvector（按团队熟悉度）

---

## 5. 任务执行链路（关键）

1. 用户请求到根节点。
2. 根节点做：鉴权 → 策略检查 → 任务分类（轻/重）。
3. 轻任务本地快速响应；重任务提交云端队列并拿到 task_id。
4. 云端执行并持续上报状态（running/progress/done/failed）。
5. 根节点向用户流式回传结果，必要时做结果脱敏与格式化。
6. 结果与审计日志分级存储（本地最小化、云端完整）。

---

## 6. 关键架构考量

### 6.1 可用性与容灾
- 根节点需具备“无云最小可用”：
  - 规则库问答
  - 本地工具（文件检索、基础命令）
- 云端多 Worker + 队列堆积保护 + 熔断限流。
- 任务状态机必须可恢复（避免根节点重启后丢任务）。

### 6.2 性能与成本
- 采用分级模型路由：
  - 简单任务走小模型，复杂任务走大模型。
- 使用响应缓存（prompt fingerprint + policy key）。
- 异步化长任务，减少用户同步等待时长。

### 6.3 安全与合规
- 端到端 TLS；根-云双向身份认证。
- 最小权限原则（每类 Worker 独立 token/scope）。
- 敏感数据分级：
  - L0 公共可上云
  - L1 受限上云（脱敏后）
  - L2 禁止上云（仅本地处理）
- 审计日志保留调用链路（谁、何时、调用了什么工具）。

### 6.4 可观测性
- 统一 trace_id 贯穿根节点与云端。
- 指标最少集：
  - p50/p95 延迟
  - 任务成功率/重试率
  - token 成本
  - 队列积压长度
- 日志采样，防止日志本身压垮低配根节点。

### 6.5 可演进性
- 协议优先（API 契约稳定），实现可替换。
- 模型供应商抽象层（避免厂商锁定）。
- 工具插件化（新增工具不影响核心控制面）。

---

## 7. 建议的分阶段落地

### Phase 1（MVP）
- 根节点：接入层 + 路由 + 策略 + 简单降级
- 云端：单区域 3 类 Worker（inference/rag/task）
- 存储：Postgres + Redis + 对象存储
- 目标：先跑通“稳定可用链路”

### Phase 2（增强）
- 引入工具沙箱与细粒度权限
- 增加模型智能路由与成本优化
- 增加审计报表与告警体系

### Phase 3（规模化）
- 多区域部署与容灾切换
- K8s 自动扩缩容
- 多租户隔离与配额系统

---

## 8. 结论（架构立场）

在“本地极低资源 + 云端可容器扩展”的前提下，最佳策略是：
- 将本地根节点定位为**轻量控制平面 + 安全边界**；
- 将云端从节点定位为**弹性执行平面**；
- 通过**异步队列、策略路由、分级安全、可观测闭环**构建稳定系统。

该方案能在当前硬件约束下实现可落地、可扩展、可治理的分布式 AI 助手架构。